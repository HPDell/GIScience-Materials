[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/HGWR/index.html",
    "href": "posts/HGWR/index.html",
    "title": "HGWR",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/DLSM/index.html",
    "href": "posts/DLSM/index.html",
    "title": "Introducing a General Framework for Locally Weighted Spatial Modelling Based on Density Regression",
    "section": "",
    "text": "In this document, I’m going to show codes of simulation experiments and their results demonstrated in the short paper Introducing a General Framework for Locally Weighted Spatial Modelling Based on Density Regression. This paper mainly talks about a density-based local spatial modelling (DLSM) method, which was originally named as “geographically weighted density regression (GWDR)”. In the following parts, we don’t distinguish these two terms.\nIn addition to show reproducable code of experiments shown in the paper, We are going to describe a bit how to install and use this model."
  },
  {
    "objectID": "posts/DLSM/index.html#two-dimensional-data",
    "href": "posts/DLSM/index.html#two-dimensional-data",
    "title": "Introducing a General Framework for Locally Weighted Spatial Modelling Based on Density Regression",
    "section": "Two-dimensional Data",
    "text": "Two-dimensional Data\n\nData Generating\nData of two dimensions (equalivent to normal geographic data) are generated by the following codes.\n\ngenerate_data_d2 <- function (size) {\n  set.seed(11)\n  U1 <- rnorm(n = size, mean = 3000, sd = 100)\n  set.seed(12)\n  U2 <- rnorm(n = size, mean = 3000, sd = 100)\n  set.seed(21)\n  x1 <- rnorm(n = size, mean = 0, sd = 1)\n  set.seed(22)\n  x2 <- rnorm(n = size, mean = 0, sd = 1)\n  set.seed(23)\n  x3 <- rnorm(n = size, mean = 0, sd = 1)\n  U1c <- (U1 - 3000) / 100\n  U2c <- (U2 - 3000) / 100\n  b0 <- U1c + U2c^2\n  b1 <- U1c + U2c^2 + 10\n  b2 <- U1c + (U2c - 1)^2\n  b3 <- U1c + U2c^2 + 2 * U2c\n  set.seed(1)\n  y <- b0 + b1 * x1 + b2 * x2 + b3 * x3 + rnorm(n = size, mean = 0, sd = 1)\n  list(\n    data = data.frame(y = y, x1 = x1, x2 = x2, x3 = x3),\n    coords = cbind(U1 = U1, U2 = U2),\n    beta = data.frame(Intercept = b0, x1 = b1, x2 = b2, x3 = b3)\n  )\n}\ndata_d2 <- generate_data_d2(5000)\nglimpse(data_d2)\n\nList of 3\n $ data  :'data.frame': 5000 obs. of  4 variables:\n  ..$ y : num [1:5000] 7.06 7.66 15.01 -14.52 37.88 ...\n  ..$ x1: num [1:5000] 0.793 0.522 1.746 -1.271 2.197 ...\n  ..$ x2: num [1:5000] -0.512 2.485 1.008 0.293 -0.209 ...\n  ..$ x3: num [1:5000] 0.193 -0.435 0.913 1.793 0.997 ...\n $ coords: num [1:5000, 1:2] 2941 3003 2848 2864 3118 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"U1\" \"U2\"\n $ beta  :'data.frame': 5000 obs. of  4 variables:\n  ..$ Intercept: num [1:5000] 1.601 2.514 -0.601 -0.516 5.169 ...\n  ..$ x1       : num [1:5000] 11.6 12.51 9.4 9.48 15.17 ...\n  ..$ x2       : num [1:5000] 5.56 0.36 2.31 2.32 10.16 ...\n  ..$ x3       : num [1:5000] -1.36 5.67 -2.51 -2.36 1.17 ...\n\n\nThen, calibrate two models: DLSM and basic GWR.\n\n\nModel: DLSM\nFirstly, we need to get a set of optimized bandwidth, each element for a dimension.\n\nd2_gwdr_bw <- gwdr.bandwidth.optimize(\n    formula = y ~ x1 + x2 + x3,\n    data = data_d2$data,\n    coords = data_d2$coords,\n    kernel.list = list(\n        gwdr.make.kernel(0.618, kernel = \"gaussian\", adaptive = T),\n        gwdr.make.kernel(0.618, kernel = \"gaussian\", adaptive = T)\n    ),\n    optimize.method = gwdr.bandwidth.optimize.aic\n)\nd2_gwdr_bw\n\n[[1]]\n[[1]][[1]]\n[1] \"gaussian\"\n\n[[1]][[2]]\n[1] 0.2243633\n\n[[1]][[3]]\n[1] TRUE\n\n\n[[2]]\n[[2]][[1]]\n[1] \"gaussian\"\n\n[[2]][[2]]\n[1] 0.008293663\n\n[[2]][[3]]\n[1] TRUE\n\n\nThen, calibrate a GWDR model with this bandwidth set.\n\nd2_gwdr <- gwdr(\n    formula = y ~ x1 + x2 + x3,\n    data = data_d2$data,\n    coords = data_d2$coords,\n    kernel.list = d2_gwdr_bw\n)\nd2_gwdr$diagnostic\n\n$R2\n[1] 0.9890828\n\n$R2.adj\n[1] 0.9838953\n\n$AICc\n[1] 19695.4\n\n\n\n\nModel: GWR\nThe GWR model for this data set can be calibrated with the following code.\n\nd2sp <- data_d2$data\ncoordinates(d2sp) <- data_d2$coords\nd2_gwr_bw <- bw.gwr(\n    formula = y ~ x1 + x2 + x3,\n    data = d2sp,\n    adaptive = T,\n    approach = \"AIC\",\n    kernel = \"gaussian\",\n    longlat = F\n)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth (number of nearest neighbours): 3097 AICc value: 28564.75 \nAdaptive bandwidth (number of nearest neighbours): 1922 AICc value: 27977.58 \nAdaptive bandwidth (number of nearest neighbours): 1194 AICc value: 27333.17 \nAdaptive bandwidth (number of nearest neighbours): 746 AICc value: 26614.68 \nAdaptive bandwidth (number of nearest neighbours): 467 AICc value: 25821.45 \nAdaptive bandwidth (number of nearest neighbours): 296 AICc value: 24986.24 \nAdaptive bandwidth (number of nearest neighbours): 189 AICc value: 24106.2 \nAdaptive bandwidth (number of nearest neighbours): 124 AICc value: 23222.91 \nAdaptive bandwidth (number of nearest neighbours): 82 AICc value: 22314.04 \nAdaptive bandwidth (number of nearest neighbours): 58 AICc value: 21556.79 \nAdaptive bandwidth (number of nearest neighbours): 41 AICc value: 20825.54 \nAdaptive bandwidth (number of nearest neighbours): 32 AICc value: 20268.46 \nAdaptive bandwidth (number of nearest neighbours): 25 AICc value: 19794.13 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 19582.89 \nAdaptive bandwidth (number of nearest neighbours): 19 AICc value: 19302.27 \nAdaptive bandwidth (number of nearest neighbours): 18 AICc value: 19213.83 \nAdaptive bandwidth (number of nearest neighbours): 16 AICc value: 18980.64 \nAdaptive bandwidth (number of nearest neighbours): 16 AICc value: 18980.64 \n\nd2_gwr <- gwr.basic(\n    formula = y ~ x1 + x2 + x3,\n    data = d2sp,\n    bw = d2_gwr_bw,\n    adaptive = T,\n    kernel = \"gaussian\",\n    longlat = F\n)\nd2_gwr\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-27 16:34:17 \n   Call:\n   gwr.basic(formula = y ~ x1 + x2 + x3, data = d2sp, bw = d2_gwr_bw, \n    kernel = \"gaussian\", adaptive = T, longlat = F)\n\n   Dependent (y) variable:  y\n   Independent variables:  x1 x2 x3\n   Number of data points: 5000\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-41.449  -2.388  -0.283   1.964  35.784 \n\n   Coefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)  1.19760    0.06607   18.13   <2e-16 ***\n   x1          11.12053    0.06613  168.17   <2e-16 ***\n   x2           2.08131    0.06610   31.49   <2e-16 ***\n   x3           1.16391    0.06631   17.55   <2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 4.671 on 4996 degrees of freedom\n   Multiple R-squared: 0.8557\n   Adjusted R-squared: 0.8556 \n   F-statistic:  9874 on 3 and 4996 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 108997.5\n   Sigma(hat): 4.669928\n   AIC:  29608.82\n   AICc:  29608.83\n   BIC:  24683.99\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 16 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                   Min.    1st Qu.     Median    3rd Qu.    Max.\n   Intercept -2.3010764  0.0021137  0.8763939  1.7517336  6.1792\n   x1         7.2879239 10.0490656 10.7414589 11.7858821 16.3170\n   x2        -1.9011456  0.2368896  1.3907690  3.0352093 12.2075\n   x3        -2.9867908 -0.6821843  0.3649609  2.1155378  9.8081\n   ************************Diagnostic information*************************\n   Number of data points: 5000 \n   Effective number of parameters (2trace(S) - trace(S'S)): 882.6782 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 4117.322 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 18980.64 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 18192.84 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 17803.57 \n   Residual sum of squares: 9849.866 \n   R-square value:  0.9869581 \n   Adjusted R-square value:  0.9841614 \n\n   ***********************************************************************\n   Program stops at: 2023-03-27 16:34:25 \n\n\nWhereas DLSM helps identify anisotropy, it is missing in estimates from a basic GWR model because the only bandwidth value optimized by GWR is 16 nearest neighbours (regardless of direction).\n\n\nAnalysis of Coefficient Estimates\nFirst, we look at the closeness between coefficient estimates and actual values.\n\nlist(DLSM = d2_gwdr$betas, GWR = d2_gwr$SDF@data) %>%\n    map(~ select(.x, Intercept, x1, x2, x3)) %>%\n    map2_dfr(., names(.), function(model, model_name) {\n        map_dfr(c(\"Intercept\", \"x1\", \"x2\", \"x3\"), ~ data.frame(\n            Estimated = model[[.x]],\n            Real = data_d2$beta[[.x]],\n            Coefficient = .x\n        ))\n    }, .id = \"Model\") %>%\n    ggplot(aes(x = Real, y = Estimated)) + geom_point() +\n    geom_abline(intercept = 0, slope = 1, color = \"darkgreen\") +\n    stat_poly_eq() + stat_poly_line() +\n    facet_grid(rows = vars(Model), cols = vars(Coefficient)) +\n    coord_fixed() + theme_bw()\n\n\n\n\nThen, we look at the RMSE and MAE criterions.\n\nlist(DLSM = d2_gwdr$betas, GWR = d2_gwr$SDF@data) %>%\n    map(~ select(.x, Intercept, x1, x2, x3)) %>%\n    map2_dfr(., names(.), function(model, model_name) {\n        map_dfr(c(\"Intercept\", \"x1\", \"x2\", \"x3\"), ~ data.frame(\n            RMSE = sqrt(mean((data_d2$beta[[.x]] - model[[.x]])^2)),\n            MAE = mean(abs(data_d2$beta[[.x]] - model[[.x]])),\n            Coefficient = .x\n        ))\n    }, .id = \"Model\") %>%\n    map_dfr(c(\"RMSE\", \"MAE\"), function(i, model) {\n        data.frame(Value = model[[i]],\n                   Indicator = i,\n                   Model = model$Model,\n                   Coefficient = model$Coefficient)\n    }, .) %>%\n    ggplot(aes(x = Coefficient, y = Value, fill = Model)) + \n    geom_col(position = \"dodge\") +\n    geom_text(aes(y = Value + 0.02, label = sprintf(\"%.2f\", Value)),\n              position = position_dodge(width = 1)) +\n    facet_grid(cols = vars(Indicator)) +\n    theme_bw() + theme(legend.position = \"top\")\n\n\n\n\n\n\nLocal Polynomial Estimator\nCoefficient estimates for some points are significantly biased in both DLSM and GWR models. Now let us try the local polynomial kernel estimation method to demonstrate some of its features. We will calibrate a DLSM model with this kernel analyse coefficient estimates in a same way.\n\nd2_gwdr_lp <- gwdr(\n    formula = y ~ x1 + x2 + x3,\n    data = data_d2$data,\n    coords = data_d2$coords,\n    kernel.list = d2_gwdr_bw,\n    solver = \"local.poly\"\n)\nd2_gwdr$diagnostic\n\n$R2\n[1] 0.9890828\n\n$R2.adj\n[1] 0.9838953\n\n$AICc\n[1] 19695.4\n\n\nThe following two figures show comparsion between estimates and real values.\n\n\n\n\n\n\n\n\nThus, the local polynomial estimator can significantly reduce estimation errors. And the boundary effects are also reduced."
  },
  {
    "objectID": "posts/DLSM/index.html#three-dimensional-data",
    "href": "posts/DLSM/index.html#three-dimensional-data",
    "title": "Introducing a General Framework for Locally Weighted Spatial Modelling Based on Density Regression",
    "section": "Three-dimensional Data",
    "text": "Three-dimensional Data\nIn most spatial modelling research, 3D data are usually referred to spatio-temporal data, i.e., data of geographical and temporal coordinates \\(u,v,t\\). For this type of data, there is a corresponding geographically and temporally weighted regression (GTWR, Huang, Wu, and Barry 2010) model. In this experiment, we compare DLSM model with this method.\n\nData\nWe created 4 sets of data through similar generation process introduced in the experiment on 2D data, named as data-3d-i where i is a value from 1 to 4. To access these data, please turn to GitHub worktree page.\n\nd3_data_list <- map(c(1:4), function(i) {\n    readRDS(sprintf(\"data/compare-gtwr-%d.rds\", i))\n})\n\nIn the first two data sets, the time coordinates were generated from a normal distributed random variable, i.e., \\(t \\sim N(1619694000, 604800^2)\\). While in the latter two data sets, \\(t\\) was generated from an arithmetic sequence with 1000 elements, a common different of 1, and a first item \\(t_0\\) of \\(1619694000\\). And the distribution of coefficients on \\(t\\)-axis follows autoregressive time series.\n\n\nModel: DLSM\nThe DLSM model can be calibrated with the following codes:\n\nd3_gwdr_list <- map(c(1:4), function (i) {\n    d3_data <- d3_data_list[[i]]\n    coords_range <- apply(d3_data$coord, 2, max) - apply(d3_data$coord, 2, min)\n    kernel <- gwdr.bandwidth.optimize(\n        formula = y ~ x1 + x2 + x3,\n        data = d3_data$data,\n        coords = d3_data$coord,\n        kernel.list = list(\n            gwdr.make.kernel(coords_range[1] * 0.618, kernel = \"bisquare\", adaptive = FALSE),\n            gwdr.make.kernel(coords_range[2] * 0.618, kernel = \"bisquare\", adaptive = FALSE),\n            gwdr.make.kernel(coords_range[3] * 0.618, kernel = \"bisquare\", adaptive = FALSE)\n        )\n    )\n    gwdr(\n        formula = y ~ x1 + x2 + x3,\n        data = d3_data$data,\n        coords = d3_data$coord,\n        kernel.list = kernel\n    )\n})\n\n\n\nModel: GTWR\nWe used the “GTWR ADDIN” for ArcMap (Huang and Wang 2020) to calibrate GTWR model for all the four data sets. This is because there is a key parameter \\(\\lambda\\) in GTWR mdoel which should be optimized according to data, just like the bandwidth. But gtwr() function in GWmodel package does not support this process. And this addin has much higher computing performance. Results are stored in the GTWR results folder. We can load them with the following codes.\n\nd3_gtwr_list <- map(c(1:4), function(i) {\n    st_read(file.path(\"gtwr_results\", sprintf(\"compare-gtwr-%d-gtwr.shp\", i)))\n})\n\nReading layer `compare-gtwr-1-gtwr' from data source \n  `C:\\Users\\rd21411\\OneDrive - University of Bristol\\Documents\\Conferences\\2023_GIScience_Materials\\posts\\DLSM\\gtwr_results\\compare-gtwr-1-gtwr.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1000 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2672.301 ymin: 2695.423 xmax: 3369.969 ymax: 3310.724\nCRS:           NA\nReading layer `compare-gtwr-2-gtwr' from data source \n  `C:\\Users\\rd21411\\OneDrive - University of Bristol\\Documents\\Conferences\\2023_GIScience_Materials\\posts\\DLSM\\gtwr_results\\compare-gtwr-2-gtwr.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1000 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2672.301 ymin: 2695.423 xmax: 3369.969 ymax: 3310.724\nCRS:           NA\nReading layer `compare-gtwr-3-gtwr' from data source \n  `C:\\Users\\rd21411\\OneDrive - University of Bristol\\Documents\\Conferences\\2023_GIScience_Materials\\posts\\DLSM\\gtwr_results\\compare-gtwr-3-gtwr.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1000 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2672.301 ymin: 2695.423 xmax: 3369.969 ymax: 3310.724\nCRS:           NA\nReading layer `compare-gtwr-4-gtwr' from data source \n  `C:\\Users\\rd21411\\OneDrive - University of Bristol\\Documents\\Conferences\\2023_GIScience_Materials\\posts\\DLSM\\gtwr_results\\compare-gtwr-4-gtwr.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1000 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2672.301 ymin: 2695.423 xmax: 3369.969 ymax: 3310.724\nCRS:           NA\n\n\n\n\nAnalysis\nWe analyse the performance of these two models based on coefficient estimates and actual values.\n\nd3_model_coef <- pmap(list(\n    DLSM = d3_gwdr_list,\n    GTWR = d3_gtwr_list,\n    Real = d3_data_list\n), function(DLSM, GTWR, Real) {\n    dlsm_coef_df <- select(DLSM$betas, Intercept, x1, x2, x3) %>%\n        map2_dfr(., names(.), ~ data.frame(\n            Model = \"DLSM\",\n            Coefficient = .y,\n            Estimate = .x,\n            Real = Real$beta[[.y]]\n        ))\n    gtwr_coef_df <- rename(GTWR, x1 = C1_x1, x2 = C2_x2, x3 = C3_x3) %>%\n        st_drop_geometry() %>%\n        select(Intercept, x1, x2, x3) %>%\n        map2_dfr(., names(.), ~ data.frame(\n            Model = \"GTWR\",\n            Coefficient = .y,\n            Estimate = .x,\n            Real = Real$beta[[.y]]\n        ))\n    rbind(dlsm_coef_df, gtwr_coef_df)\n})\n\n\nd3_model_coef %>%\n    map(function(item) {\n        scatter <- ggplot(item, aes(Real, Estimate)) +\n            geom_point() +\n            geom_abline(intercept = 0, slope = 1) +\n            geom_smooth(method = \"lm\") +\n            stat_poly_eq(use_label(\"adj.rr.label\")) +\n            facet_grid(rows = vars(Coefficient), cols = vars(Model)) +\n            coord_fixed() + theme_bw()\n        bar <- item %>%\n            group_by(Coefficient, Model) %>%\n            summarise(RMSE = rmse(Real, Estimate), MAE = mae(Real, Estimate)) %>%\n            ungroup() %>%\n            melt(id.vars = c(\"Coefficient\", \"Model\"), variable.name = \"Indicator\", value.name = \"Value\") %>%\n            ggplot(aes(Coefficient, Value, fill = Model)) +\n                geom_col(position = \"dodge\") +\n                geom_text(aes(label = sprintf(\"%.2f\", Value)), size = 2,\n                        position = position_dodge(1), vjust = -0.5) +\n                facet_grid(rows = vars(Indicator)) +\n                theme_bw()\n        ggarrange(scatter, bar, nrow = 1)\n    }) %>%\n    walk2(., 1:4, function(fig, i) {\n        print(annotate_figure(fig, bottom = sprintf(\"Data set %d\", i)))\n    })\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccording to the results, DLSM can reduce the mean of absolute estimation error by 10%-50%, especially when coefficients are temporally autocorrelated. The multiple bandwidths attach actual meaning to the parameters \\(\\lambda,\\mu\\); they have a real-world correlate, unlike the root of sum of squared meters and seconds (\\(\\sqrt{\\mathrm{m}^2+\\mathrm{s}^2}\\))."
  },
  {
    "objectID": "posts/DLSM/index.html#four-dimensional-data",
    "href": "posts/DLSM/index.html#four-dimensional-data",
    "title": "Introducing a General Framework for Locally Weighted Spatial Modelling Based on Density Regression",
    "section": "Four-dimensional Data",
    "text": "Four-dimensional Data\nFour-dimensional data are not so common in our daily life. But there is an special example — travel flow. Each flow is a directed line consisting of a origin point and destination point. Thus, flow data are also called O-D data. For a 2D coordinate reference system, both the origin point and desitnation point have a 2D coordinates. Totally, there are 4 coordinates to locate a flow. By converting the four positional coordinates to a set of coordinates of origin point \\((x,y)\\), direction \\(\\theta\\), and flow length \\(l\\), we will get a space of four dimensions \\((x,y,\\theta,l)\\). The experiment is based on this space.\n\nData Generating\nData of four dimensions are generated by the following codes.\n\ngenerate_data_d4 <- function (size) {\n  set.seed(11)\n  U1 <- rnorm(n = size, mean = 3000, sd = 100)\n  set.seed(12)\n  U2 <- rnorm(n = size, mean = 3000, sd = 100)\n  set.seed(13)\n  U3 <- runif(n = size, min = -pi, max = pi)\n  set.seed(14)\n  U4 <- rnorm(n = size, mean = 4000, sd = 1000)\n  set.seed(21)\n  x1 <- rnorm(n = size, mean = 0, sd = 1)\n  set.seed(22)\n  x2 <- rnorm(n = size, mean = 0, sd = 1)\n  set.seed(23)\n  x3 <- rnorm(n = size, mean = 0, sd = 1)\n  b0 <- scale(((U1 - 3000)/100) + ((U2 - 3000)/100)^2 + ((U4 - 4000)/1000)^2)\n  b1 <- scale(((U1 - 3000)/100) + ((U2 - 3000)/100)^2 + ((U4 - 4000)/1000)^2)\n  b2 <- scale(((U1 - 3000)/100) + 5 * ((U2 - 3000)/100)^2 + ((U4 - 4000)/1000)^2)\n  b3 <- scale(-((U1 - 3000)/100) + ((U2 - 3000)/100)^2 + ((U4 - 4000)/1000)^2)\n  set.seed(1)\n  y <- b0 + b1 * x1 + b2 * x2 + b3 *x3 + rnorm(n = size, mean = 0, sd = 1)\n  list(\n    data = data.frame(y = y, x1 = x1, x2 = x2, x3 = x3),\n    coords = cbind(U1 = U1, U2 = U2, U3 = U3, U4 = U4),\n    beta = data.frame(Intercept = b0, x1 = b1, x2 = b2, x3 = b3)\n  )\n}\ndata_d4 <- generate_data_d4(5000)\n\n\n\nModel: DLSM\nThe DLSM model can be calibrated by the following code.\n\nd4_gwdr_bw <- gwdr.bandwidth.optimize(\n    formula = y ~ x1 + x2 + x3,\n    data = data_d4$data,\n    coords = data_d4$coords,\n    kernel.list = list(\n        gwdr.make.kernel(0.618, kernel = \"bisquare\", adaptive = T),\n        gwdr.make.kernel(0.618, kernel = \"bisquare\", adaptive = T),\n        gwdr.make.kernel(0.618, kernel = \"bisquare\", adaptive = T),\n        gwdr.make.kernel(0.618, kernel = \"bisquare\", adaptive = T)\n    )\n)\nd4_gwdr <- gwdr(\n    formula = y ~ x1 + x2 + x3,\n    data = data_d4$data,\n    coords = data_d4$coords,\n    kernel.list = d4_gwdr_bw\n)\nd4_gwdr$diagnostic\n\n$R2\n[1] 0.8242963\n\n$R2.adj\n[1] 0.7287304\n\n$AICc\n[1] 17255.57\n\n\n\n\nModel: GWR\nTo calibrate a GWR model, we need to calculate the distance matrix first because gwr.basic() is not able to calculate distances for lines. Distance between two flows \\(\\overrightarrow{O_iD_i}\\) and \\(\\overrightarrow{O_jD_j}\\) are defined by \\[\nd_{ij}=\\sqrt{\\frac{\n    0.5 \\times \\left[ (O_{ix}-O_{jx})^2 + (O_{iy}-O_{jy})^2 \\right] +\n    0.5 \\times \\left[ (D_{ix}-D_{jx})^2 + (D_{iy}-D_{jy})^2 \\right]\n}{l_i l_j}}\n\\] where \\((O_{ix},O_{iy})\\) is the coordinate of \\(O_i\\), \\((O_{jx},O_{jy})\\) is the coordinate of \\(O_j\\), \\((D_{ix},D_{iy})\\) is the coordinate of \\(D_i\\), \\((D_{jx},D_{jy})\\) is the coordinate of \\(D_j\\), and \\(l_i,l_j\\) are length of flows \\(\\overrightarrow{O_iD_i}\\) and \\(\\overrightarrow{O_jD_j}\\).\nThis is implementated by the following codes.\n\nd4_origin <- data_d4$coords[, 1:2]\nd4_dest <- d4_origin + with(as.data.frame(data_d4$coords), matrix(cbind(U4 * cos(U3), U4 * sin(U3)), ncol = 2))\nd4_od <- cbind(d4_origin, d4_dest, data_d4$coords[, 3:4])\ncolnames(d4_od) <- c(\"ox\", \"oy\", \"dx\", \"dy\", \"angle\", \"length\")\nd4_dmat <- apply(d4_od, MARGIN = 1, FUN = function(x) {\n    sqrt(colSums((t(d4_od[,1:4]) - x[1:4])^2) / 2 / x[\"length\"] / d4_od[, \"length\"])\n})\nd4_dmat[1:5,1:5]\n\n          [,1]      [,2]      [,3]      [,4]      [,5]\n[1,] 0.0000000 1.4077782 1.2585313 1.3656097 0.9873034\n[2,] 1.4077782 0.0000000 0.5916647 0.6618936 1.0783478\n[3,] 1.2585313 0.5916647 0.0000000 1.1402567 1.3717634\n[4,] 1.3656097 0.6618936 1.1402567 0.0000000 0.5994136\n[5,] 0.9873034 1.0783478 1.3717634 0.5994136 0.0000000\n\n\nThen use the distance matrix d4_dmat as weighting criterion in GWR.\n\nd4sp <- cbind(data_d4$data)\ncoordinates(d4sp) <- data_d4$coords[,1:2]\nd4_gwr_bw <- bw.gwr(\n    formula = y ~ x1 + x2 + x3, data = d4sp,\n    adaptive = T, dMat = d4_dmat\n)\n\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth: 3097 CV score: 27063.63 \nAdaptive bandwidth: 1922 CV score: 26809.04 \nAdaptive bandwidth: 1194 CV score: 26172.95 \nAdaptive bandwidth: 746 CV score: 25282.31 \nAdaptive bandwidth: 467 CV score: 24435.03 \nAdaptive bandwidth: 296 CV score: 23756.82 \nAdaptive bandwidth: 189 CV score: 23263.05 \nAdaptive bandwidth: 124 CV score: 22945.49 \nAdaptive bandwidth: 82 CV score: 22825.49 \nAdaptive bandwidth: 58 CV score: 22944.28 \nAdaptive bandwidth: 98 CV score: 22847.02 \nAdaptive bandwidth: 72 CV score: 22835.85 \nAdaptive bandwidth: 87 CV score: 22844.34 \nAdaptive bandwidth: 77 CV score: 22829.18 \nAdaptive bandwidth: 83 CV score: 22829.85 \nAdaptive bandwidth: 79 CV score: 22825.71 \nAdaptive bandwidth: 81 CV score: 22821.32 \nAdaptive bandwidth: 83 CV score: 22829.85 \nAdaptive bandwidth: 82 CV score: 22825.49 \nAdaptive bandwidth: 83 CV score: 22829.85 \nAdaptive bandwidth: 82 CV score: 22825.49 \nAdaptive bandwidth: 82 CV score: 22825.49 \nAdaptive bandwidth: 81 CV score: 22821.32 \n\nd4_gwr <- gwr.basic(\n    formula = y ~ x1 + x2 + x3, data = d4sp,\n    bw = d4_gwr_bw, adaptive = T, dMat = d4_dmat\n)\nd4_gwr\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-28 17:49:16 \n   Call:\n   gwr.basic(formula = y ~ x1 + x2 + x3, data = d4sp, bw = d4_gwr_bw, \n    adaptive = T, dMat = d4_dmat)\n\n   Dependent (y) variable:  y\n   Independent variables:  x1 x2 x3\n   Number of data points: 5000\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-19.6256  -1.2957  -0.1548   1.0775  28.6380 \n\n   Coefficients:\n                Estimate Std. Error t value Pr(>|t|)   \n   (Intercept) -0.003055   0.032933  -0.093  0.92609   \n   x1           0.054850   0.032961   1.664  0.09616 . \n   x2           0.093825   0.032946   2.848  0.00442 **\n   x3           0.062644   0.033052   1.895  0.05811 . \n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 2.328 on 4996 degrees of freedom\n   Multiple R-squared: 0.002916\n   Adjusted R-squared: 0.002317 \n   F-statistic:  4.87 on 3 and 4996 DF,  p-value: 0.002203 \n   ***Extra Diagnostic information\n   Residual sum of squares: 27080.44\n   Sigma(hat): 2.327715\n   AIC:  22646.25\n   AICc:  22646.27\n   BIC:  17721.43\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: bisquare \n   Adaptive bandwidth: 81 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: A distance matrix is specified for this model calibration.\n\n   ****************Summary of GWR coefficient estimates:******************\n                  Min.   1st Qu.    Median   3rd Qu.   Max.\n   Intercept -1.429833 -0.486051 -0.203637  0.148622 2.9955\n   x1        -1.110369 -0.443654 -0.171952  0.183283 4.6331\n   x2        -1.010210 -0.334072 -0.071004  0.203844 3.4854\n   x3        -1.396231 -0.456705 -0.169986  0.212258 3.3622\n   ************************Diagnostic information*************************\n   Number of data points: 5000 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1119.033 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 3880.967 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 21308.13 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 20202.63 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 21205.94 \n   Residual sum of squares: 14187.55 \n   R-square value:  0.4776237 \n   Adjusted R-square value:  0.3269636 \n\n   ***********************************************************************\n   Program stops at: 2023-03-28 17:49:20 \n\n\n\n\nAnalysis\nCloseness between coefficient estimates and actual values are shown in the following figure.\n\nlist(DLSM = d4_gwdr$betas, GWR = d4_gwr$SDF@data) %>%\n    map(~ select(.x, Intercept, x1, x2, x3)) %>%\n    map2_dfr(., names(.), function(model, model_name) {\n        map_dfr(c(\"Intercept\", \"x1\", \"x2\", \"x3\"), ~ data.frame(\n            Estimated = model[[.x]],\n            Real = data_d4$beta[[.x]],\n            Model = model_name,\n            Coefficient = .x\n        ))\n    }) %>%\n    ggplot(aes(x = Real, y = Estimated)) + geom_point() +\n    geom_abline(intercept = 0, slope = 1, color = \"darkgreen\") +\n    stat_poly_eq() + stat_poly_line() +\n    facet_grid(rows = vars(Model), cols = vars(Coefficient)) +\n    theme_bw()\n\n\n\n\nRMSE and MAE evaluations are shown in the following figure.\n\nlist(DLSM = d4_gwdr$betas, GWR = d4_gwr$SDF@data) %>%\n    map(~ select(.x, Intercept, x1, x2, x3)) %>%\n    map2_dfr(., names(.), function(model, model_name) {\n        map_dfr(c(\"Intercept\", \"x1\", \"x2\", \"x3\"), ~ data.frame(\n            RMSE = sqrt(mean((data_d4$beta[[.x]] - model[[.x]])^2)),\n            MAE = mean(abs(data_d4$beta[[.x]] - model[[.x]])),\n            Model = model_name,\n            Coefficient = .x\n        ))\n    }) %>%\n    map_dfr(c(\"RMSE\", \"MAE\"), function(i, model) {\n        data.frame(Value = model[[i]],\n                   Indicator = i,\n                   Model = model$Model,\n                   Coefficient = model$Coefficient)\n    }, .) %>%\n    ggplot(aes(x = Coefficient, y = Value, fill = Model)) + \n    geom_col(position = \"dodge\") +\n    geom_text(aes(y = Value + 0.02, label = sprintf(\"%.2f\", Value)),\n              position = position_dodge(width = 1)) +\n    facet_grid(cols = vars(Indicator)) +\n    theme_bw() + theme(legend.position = \"top\")\n\n\n\n\nResults show that DLSM works well for spatial line data even without defining distance metrics. It performs better than GWR according to mean of estimation errors, but a few outliers exist in estimates. GWR selected a much smaller bandwidth (173 neighbours). Thus, the risk of overfitting reappears."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Contents",
    "section": "",
    "text": "HGWR\n\n\n\n\n\n\n\n\n\n\n\n\nMar 25, 2023\n\n\nYigong Hu\n\n\n\n\n\n\n\n\nIntroducing a General Framework for Locally Weighted Spatial Modelling Based on Density Regression\n\n\n\n\n\n\n\n\n\n\n\n\nMar 22, 2023\n\n\nYigong Hu\n\n\n\n\n\n\nNo matching items"
  }
]