{
  "hash": "a084862619a49a3259828e0cd5ee9a93",
  "result": {
    "markdown": "---\ntitle: \"A Hierarchical and Geographically Weighted Regression Model and Its Backfitting Maximum Likelihood Estimator\"\nauthor: \"Yigong Hu\"\ndate: \"2023-03-25\"\nexecute: \n    cache: true\n---\n\n\nHierarchical and geographically weighted regression (HGWR) is a spatial modelling method designed for data with a spatially hierarchical structure,\ni.e., samples are grouped by their locations.\nVariables are divied into group level and sample level.\nIt calibrate three types of effects: local fixed effects, global fixed effects, and random effects.\nOnly group level variables can be local fixed effects.\nIn this post, the usage and some examples are going to be shown with R code.\n\n# Installation\n\nThe HGWR model is implemented with C++ and R codes.\nAnd we have published an R package **hgwrr** to provice easy-to-use user interfaces to build HGWR moddels.\n\n## From CRAN\n\nInstall the **hgwrr** package from CRAN is very easy, through\n\n```r\ninstall.packages(\"hgwrr\")\n```\n\nNote if you are using Linux or macOS platforms, this package requires GSL to be installed and can be found by R.\nPlease install it using your package manager, like `apt`, `dnf`, and `brew`.\nOn Windows, the pre-built binary package would be provided by CRAN.\n\n## From Source Code\n\nPlease download the [R source package (v0.3.0)] and install it via the following code\n\n```bash\nR CMD INSTALL hgwrr_0.3-0.tar.gz\n```\n\nPlease make sure that the following dependencies are already installed in your R environment:\n\n- Armadillo\n- GSL\n\nJust the package-manager versions are enough.\n\n# Usage\n\nAn HGWR model can be calibrated using the following function,\n\n```r\nhgwr(\n  formula, data, local.fixed, coords, bw,\n  alpha = 0.01, eps_iter = 1e-06, eps_gradient = 1e-06, max_iters = 1e+06,\n  max_retries = 1e+06, ml_type = HGWR_ML_TYPE_D_ONLY, verbose = 0\n)\n```\n\nThere seems to be quite a few arguments, but most of them have default values which would be fine on most ocassions.\nThe first five arguments are mandatory.\n\n`formula`\n: This argument accepts a formula object in R. Its format follows lme4 package.\nAs there are two types of effects: fixed effects and random effects,\nwe use the following format to specify both of them\n    \n    ```r\n    dependent ~ fixed1 + fixed2 + (random1 + random2 | group)\n    ```\n\n`data`\n: It accepts a DataFrame object in R. All variables specified in formula are extracted from data.\nIn this stage, `Spatial*DataFrame` is not supported, and will not be supported in the future.\n\n`local.fixed`\n: It accepts a list of character specifying which fixed effects are local.\nFor example, if `fixed1` needs to be locally fixed, then set `local.fixed` to `c(\"fixed1\")`.\n\n`coords`\n: It accepts a matrix of 2 columns. Each row is the longitude and latitude of each group.\n\n`bw`\n: It accepts an integer or numeric number to specify the bandwidth used in geographically weighted process.\nCurrently, it can only be adaptive bandwidth.\n\nFor other arguments, if the default values cause some problems, and you want to change some of them,\nplease check the documentation of function hgwr() for more infomation.\n\n# Simulation Experiment\n\nTo carry out the experiment, there are some packages required to be in your R environment.\nPlease install them if they are abscent.\n\n- tidyverse\n- ggpmisc\n- ggpubr\n- Metrics\n- sf\n- MASS\n- GWmodel\n- lmerTest\n- performance\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-1_08948a4834dc628b0052db15397a92c9'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggpubr)\nlibrary(Metrics)\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n```\n:::\n\n```{.r .cell-code}\nlibrary(hgwrr)\nlibrary(GWmodel)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: maptools\nLoading required package: sp\nChecking rgeos availability: TRUE\nPlease note that 'maptools' will be retired during 2023,\nplan transition at your earliest convenience;\nsome functionality will be moved to 'sp'.\nLoading required package: robustbase\nLoading required package: Rcpp\nLoading required package: spatialreg\nLoading required package: spData\nTo access larger datasets in this package, install the spDataLarge\npackage with: `install.packages('spDataLarge',\nrepos='https://nowosad.github.io/drat/', type='source')`\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nWelcome to GWmodel version 2.2-9.\n```\n:::\n\n```{.r .cell-code}\nlibrary(lmerTest)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lme4\n\nAttaching package: 'lmerTest'\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\nThe following object is masked from 'package:robustbase':\n\n    carrots\n\nThe following object is masked from 'package:stats':\n\n    step\n```\n:::\n:::\n\n\n\n## Data Generation\n\nThe data used in this experiment is generated by the following code.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_5dabf574d1ac70570a67b41657865240'}\n\n```{.r .cell-code}\nnu <- 25\nnv <- 25\nncoords <- nu * nv\ncoords <- matrix(c(rep(seq_len(nu) - 1, each = 25), rep(seq_len(nv) - 1, times = 25)), ncol = 2) %>% as.data.frame()\ncolnames(coords) <- c(\"u\", \"v\")\nu <- coords[[\"u\"]]\nv <- coords[[\"v\"]]\ng1 <- (36 - (6 - u/2)^2)*(36 - (6 - v/2)^2)/324\ng2 <- 4 * exp(- (scale(u)^2 + scale(v)^2)/2)\nh1 <- rep(2, times = ncoords)\nset.seed(648)\nz1 <- rnorm(ncoords, mean = 2, sd = 0.5)\nset.seed(12574)\nb0 <- (u + v) / 12 - 2 + rnorm(ncoords, mean = 2, sd = 0.2)\nbetas <- data.frame(Intercept = b0, g1, g2, h1, z1)\nset.seed(648)\nnsamples <- floor(runif(ncoords, 20, 50))\niloc <- rep(seq_len(ncoords), times = nsamples)\nset.seed(1)\nx <- MASS::mvrnorm(sum(nsamples), mu = rep(0, 4), Sigma = diag(4))\nx[,1] <- aggregate(x[,1], by = list(iloc), FUN = mean)[[\"x\"]] %>% rep(times = nsamples)\nx[,2] <- aggregate(x[,2], by = list(iloc), FUN = mean)[[\"x\"]] %>% rep(times = nsamples)\ncolnames(x) <- c(\"g1\", \"g2\", \"h1\", \"z1\")\nset.seed(2)\ne <- rnorm(sum(nsamples))\ny <- rowSums(cbind(1, x) * as.matrix(betas[iloc,])) + e\ndata <- cbind(y = y, x, group = iloc) %>% as.data.frame()\nsim <- list(\n    data = data,\n    betas = betas,\n    coords = coords\n)\nsim_sf <- st_as_sf(with(sim, cbind(data, coords[data$group,])), coords = c(\"u\", \"v\"))\nglimpse(sim)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 3\n $ data  :'data.frame':\t21434 obs. of  6 variables:\n  ..$ y    : num [1:21434] 4.274 0.952 -2.278 1.21 4.547 ...\n  ..$ g1   : num [1:21434] -0.154 -0.154 -0.154 -0.154 -0.154 ...\n  ..$ g2   : num [1:21434] 0.109 0.109 0.109 0.109 0.109 ...\n  ..$ h1   : num [1:21434] 3.169 -0.031 -1.092 -0.983 1.719 ...\n  ..$ z1   : num [1:21434] -0.626 0.184 -0.836 1.595 0.33 ...\n  ..$ group: num [1:21434] 1 1 1 1 1 1 1 1 1 1 ...\n $ betas :'data.frame':\t625 obs. of  5 variables:\n  ..$ Intercept: num [1:625] 0.35 0.429 0.33 0.267 0.465 ...\n  ..$ g1       : num [1:625] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ g2       : num [1:625] 0.252 0.314 0.384 0.461 0.543 ...\n  ..$ h1       : num [1:625] 2 2 2 2 2 2 2 2 2 2 ...\n  ..$ z1       : num [1:625] 2.46 2.63 1.25 1.91 1.91 ...\n $ coords:'data.frame':\t625 obs. of  2 variables:\n  ..$ u: num [1:625] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ v: num [1:625] 0 1 2 3 4 5 6 7 8 9 ...\n```\n:::\n:::\n\n\nWith this data, we are going to calibrate a HGWR, GWR, and HLM models.\nThe multiscale GWR (MGWR) requires a very large amout of memory and time,\nso we only demonstrate the workable codes here.\nThe result we got on a high-performance computing platform is used instead.\n\n## Model Calibration\n\n### HGWR\n\nA HGWR model is calibrated with the following code.\n\n\n::: {.cell hash='index_cache/html/sim-hgwr-model_cdd7e88b5519f1bbfdcbd75bc238fcef'}\n\n```{.r .cell-code}\nhgwr_formula <- y ~ g1 + g2 + h1 + (z1 | group)\nhgwr_model <- hgwr(\n    hgwr_formula, sim$data, c(\"g1\", \"g2\"), sim$coords, \"CV\", \n    kernel = \"bisquared\",\n)\nsummary(hgwr_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHierarchical and geographically weighted regression model\n=========================================================\nFormula: hgwr_formula\n Method: Back-fitting and Maximum likelihood\n   Data: sim$data\n\nDiagnostics\n-----------\n Rsquared \n 0.908050 \n\nScaled residuals\n----------------\n       Min         1Q    Median        3Q       Max \n -3.995269  -0.648274  0.000561  0.652537  3.530948 \n\nOther Information\n-----------------\nNumber of Obs: 21434\n       Groups: group , 625\n```\n:::\n:::\n\n\n### GWR\n\n\n::: {.cell hash='index_cache/html/sim-gwr-model_dd6f6c4019ac997ab9d0037bca436e29'}\n\n```{.r .cell-code}\nsim_sp <- as(sim_sf, Class = \"Spatial\")\ngwr_formula <- y ~ g1 + g2 + h1 + z1\ngwr_bw <- bw.gwr(gwr_formula, sim_sp, approach = \"AIC\", adaptive = T, kernel = \"bisquare\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTake a cup of tea and have a break, it will take a few minutes.\n          -----A kind suggestion from GWmodel development group\nAdaptive bandwidth (number of nearest neighbours): 13254 AICc value: 68302.68 \nAdaptive bandwidth (number of nearest neighbours): 8199 AICc value: 67235.53 \nAdaptive bandwidth (number of nearest neighbours): 5074 AICc value: 66677.95 \nAdaptive bandwidth (number of nearest neighbours): 3143 AICc value: 66381.08 \nAdaptive bandwidth (number of nearest neighbours): 1949 AICc value: 66152.06 \nAdaptive bandwidth (number of nearest neighbours): 1212 AICc value: 65879.63 \nAdaptive bandwidth (number of nearest neighbours): 755 AICc value: 65553.06 \nAdaptive bandwidth (number of nearest neighbours): 474 AICc value: 65089.52 \nAdaptive bandwidth (number of nearest neighbours): 299 AICc value: 64121.17 \nAdaptive bandwidth (number of nearest neighbours): 192 AICc value: 113016 \nAdaptive bandwidth (number of nearest neighbours): 366 AICc value: 64842.55 \nAdaptive bandwidth (number of nearest neighbours): 258 AICc value: 63736.27 \nAdaptive bandwidth (number of nearest neighbours): 232 AICc value: 63688.32 \nAdaptive bandwidth (number of nearest neighbours): 216 AICc value: 64235.33 \nAdaptive bandwidth (number of nearest neighbours): 241 AICc value: 63684.82 \nAdaptive bandwidth (number of nearest neighbours): 248 AICc value: 63701.3 \nAdaptive bandwidth (number of nearest neighbours): 238 AICc value: 63682.91 \nAdaptive bandwidth (number of nearest neighbours): 235 AICc value: 63681.33 \nAdaptive bandwidth (number of nearest neighbours): 234 AICc value: 63681.33 \n```\n:::\n\n```{.r .cell-code}\ngwr_model <- gwr.basic(gwr_formula, sim_sp, bw = gwr_bw, adaptive = T, kernel = \"bisquare\")\ngwr_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-30 11:46:44 \n   Call:\n   gwr.basic(formula = gwr_formula, data = sim_sp, bw = gwr_bw, \n    kernel = \"bisquare\", adaptive = T)\n\n   Dependent (y) variable:  y\n   Independent variables:  g1 g2 h1 z1\n   Number of data points: 21434\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-5.6729 -0.9458 -0.0075  0.9499  5.3801 \n\n   Coefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n   (Intercept) 2.002434   0.009684  206.78   <2e-16 ***\n   g1          1.659038   0.057600   28.80   <2e-16 ***\n   g2          1.791212   0.056544   31.68   <2e-16 ***\n   h1          2.010065   0.009660  208.09   <2e-16 ***\n   z1          2.042761   0.009661  211.44   <2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 1.417 on 21429 degrees of freedom\n   Multiple R-squared: 0.8064\n   Adjusted R-squared: 0.8064 \n   F-statistic: 2.232e+04 on 4 and 21429 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 43019.04\n   Sigma(hat): 1.416769\n   AIC:  75771.36\n   AICc:  75771.37\n   BIC:  54445.03\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: bisquare \n   Adaptive bandwidth: 234 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                 Min.  1st Qu.   Median  3rd Qu.    Max.\n   Intercept -0.36804  1.37847  1.98864  2.63158  3.8950\n   g1        -5.46208  0.37769  1.59423  2.78590 11.7942\n   g2        -5.90918  0.79411  1.74163  2.85702 13.1842\n   h1         1.51922  1.94629  2.01310  2.07438  2.3601\n   z1         1.14097  1.83026  2.01883  2.21836  2.8169\n   ************************Diagnostic information*************************\n   Number of data points: 21434 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1348.983 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 20085.02 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 63681.33 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 62482 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 50756.14 \n   Residual sum of squares: 22014.71 \n   R-square value:  0.9009503 \n   Adjusted R-square value:  0.8942974 \n\n   ***********************************************************************\n   Program stops at: 2023-03-30 11:47:26 \n```\n:::\n:::\n\n\n### HLM\n\n\n::: {.cell hash='index_cache/html/sim-hlm-model_58ff94dfeba8203e355a476b50ff1fe2'}\n\n```{.r .cell-code}\nhlm_model <- lmerTest::lmer(y ~ g1 + g2 + h1 + z1 + (z1 | group), sim$data)\nsummary(hlm_model)\nperformance::r2(hlm_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: y ~ g1 + g2 + h1 + z1 + (z1 | group)\n   Data: sim$data\n\nREML criterion at convergence: 64443.4\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9791 -0.6478  0.0011  0.6521  3.5484 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n group    (Intercept) 0.7750   0.8804       \n          z1          0.2511   0.5011   0.01\n Residual             1.0087   1.0044       \nNumber of obs: 21434, groups:  group, 625\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(>|t|)    \n(Intercept) 1.991e+00  3.595e-02 6.202e+02  55.377  < 2e-16 ***\ng1          1.581e+00  2.093e-01 6.230e+02   7.552 1.53e-13 ***\ng2          1.805e+00  1.988e-01 6.261e+02   9.079  < 2e-16 ***\nh1          2.014e+00  7.043e-03 2.037e+04 286.022  < 2e-16 ***\nz1          2.026e+00  2.136e-02 6.228e+02  94.830  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n   (Intr) g1     g2     h1    \ng1  0.007                     \ng2  0.021 -0.041              \nh1  0.000 -0.001  0.000       \nz1  0.007  0.001  0.000  0.002\n# R2 for Mixed Models\n\n  Conditional R2: 0.902\n     Marginal R2: 0.803\n```\n:::\n:::\n\n\n### MGWR\n\n\n::: {.cell hash='index_cache/html/sim-mgwr-model_5f019d77398cec7b34c1866c24826fdc'}\n\n```{.r .cell-code}\nmgwr_model <- gwr.multiscale(y ~ g1 + g2 + h1 + z1, sim_sp, adaptive = T)\nmgwr_model\n```\n:::\n\n::: {.cell hash='index_cache/html/sim-mgwr-model-load_989b8f285a324f2ffd4463befb11e3e5'}\n::: {.cell-output .cell-output-stdout}\n```\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-01-07 00:33:30 \n   Call:\n   gwr.multiscale(formula = y ~ g1 + g2 + h1 + z1, data = sim_sp, \n    adaptive = T, hatmatrix = F, parallel.method = \"omp\", parallel.arg = 48)\n\n   Dependent (y) variable:  y\n   Independent variables:  g1 g2 h1 z1\n   Number of data points: 21434\n   ***********************************************************************\n   *                       Multiscale (PSDM) GWR                          *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: bisquare \n   Adaptive bandwidths for each coefficient(number of nearest neighbours): \n              (Intercept)    g1    g2    h1 z1\n   Bandwidth          382  1054   474 19875 62\n\n   ****************Summary of GWR coefficient estimates:******************\n                  Min.   1st Qu.    Median   3rd Qu.   Max.\n   Intercept  0.244383  1.451943  1.998243  2.611283 3.8138\n   g1        -0.072043  0.746596  1.426176  2.567027 4.2021\n   g2        -1.955412  0.969786  1.738936  2.659654 4.9470\n   h1         2.003644  2.010011  2.015701  2.019937 2.0227\n   z1         0.287334  1.691472  2.039915  2.376235 3.5291\n   ************************Diagnostic information*************************\n\n   ***********************************************************************\n   Program stops at: 2023-01-07 04:58:17 \n```\n:::\n:::\n\n\n## Estimate Analysis\n\nAs the actual values of coefficients are already known,\nwe can compare the performance of these models by comparing the closeness between their estimates and actual values.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_fe04ee99b62cd304fc6a0c10c39da710'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Create some handy variables.\"}\ncoef_names <- c(\"Intercept\", \"g1\", \"g2\", \"h1\", \"z1\")\ncoef_names_plot <- c(\"Intercept\", \"g1\", \"g2\", \"z1\")\ncoef_name_map <- list(\n    Intercept = \"alpha[0]\",\n    g1 = \"gamma[1]\",\n    g2 = \"gamma[2]\",\n    h1 = \"beta[1]\",\n    x1 = \"beta[1]\",\n    z1 = \"mu[1]\"\n)\ncoef_name_labels <- list(\n    Intercept = bquote(alpha[0]),\n    g1 = bquote(gamma[1]),\n    g2 = bquote(gamma[2]),\n    h1 = bquote(beta[1]),\n    x1 = bquote(beta[1]),\n    z1 = bquote(mu[1])\n)\nmodels_name <- c(\"GWR\", \"MGWR\", \"HLM\", \"HGWR\")\n```\n:::\n\n\nFirstly, we collect coefficient estimates.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_534e27890df70aa89c1aeb9074140313'}\n\n```{.r .cell-code}\n### Real values\nbeta0 <- sim$betas[coef_names]\n### HGWR\nhgwr_betas <- coef(hgwr_model)[coef_names]\n### GWR\ngwr_betas <- gwr_model$SDF@data[coef_names] %>%\n    aggregate(by = list(sim$data$group), FUN = mean) %>%\n    as.tibble() %>%\n    select(all_of(coef_names))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n```\n:::\n\n```{.r .cell-code}\n### MGWR\nmgwr_betas <- mgwr_model$SDF@data[coef_names] %>%\n    aggregate(by = list(sim$data$group), FUN = mean) %>%\n    as.tibble() %>%\n    select(all_of(coef_names))\n### HLM\nhlm_betas <- coef(hlm_model)$group\ncolnames(hlm_betas)[1] <- \"Intercept\"\nhlm_betas <- hlm_betas[coef_names]\nmodels_coef <- map(models_name, ~ get(paste0(tolower(.x), \"_betas\")))\nnames(models_coef) <- models_name\nmodels_coef_real <- c(list(Real = beta0), models_coef)\n```\n:::\n\n\nThen, plot estimate values at their location and the real values to see their distributions.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_d9dc585788a997f5c286d393532ea7e3'}\n\n```{.r .cell-code}\nmodels_coef_real %>%\n    map_dfr(function(x) {\n        select(x, all_of(coef_names)) %>%\n            map_dfr(~ data.frame(Value = .x, sim$coords), .id = \"Coefficient\")\n    }, .id = \"Algorithm\") %>% \n    mutate(Algorithm = ordered(as.factor(Algorithm), names(models_coef_real)),\n           Coefficient = ordered(as.factor(Coefficient), coef_names, \n                                 labels = coef_name_map[coef_names])) %>%\n    ggplot(aes(u, v, fill = Value)) + geom_raster() + \n        scale_x_continuous(expand = expansion()) +\n        scale_y_continuous(expand = expansion()) +\n        scale_fill_gradient2(limits = c(0, 4), low = \"#000099\", \n                             mid = \"#CCFF33\", high = \"#CC0033\",\n                             midpoint = 2, oob = scales::squish) +\n        facet_grid(rows = vars(Algorithm), cols = vars(Coefficient), labeller = label_parsed) +\n        coord_fixed() + theme_bw() +\n        theme(legend.position = \"bottom\", legend.key.height = unit(10, \"pt\")) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\nA scatter plot along with it may be useful.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-6_dac426593da5553d3b19c9f993de7188'}\n\n```{.r .cell-code}\nbeta_hat_real <- models_coef %>%\n    map_dfr(function(x) {\n        map_dfr(coef_names, ~ data.frame(Coefficient = .x, Estimated = x[[.x]], Real = beta0[[.x]]))\n    }, .id = \"Algorithm\") %>%\n    mutate(Algorithm = ordered(as.factor(Algorithm), names(models_coef)),\n           Coefficient = ordered(as.factor(Coefficient), coef_names, labels = coef_name_map[coef_names]))\nbeta_hat_rmse <- beta_hat_real %>%\n    group_nest(Algorithm, Coefficient) %>%\n    mutate(rmse = map(data, ~ sqrt(mean((.x$Estimated - .x$Real)^2))),\n           data = NULL)\nggplot(beta_hat_real, aes(x = Real, y = Estimated)) +\n    geom_point() + geom_abline(intercept = 0, slope = 1) +\n    geom_text(aes(x = -Inf, y = Inf, label = sprintf(\"RMSE=%.3f\", rmse)),\n              data = beta_hat_rmse, hjust = 0, vjust = 1.2) +\n    scale_y_continuous(limits = c(-5, 10), oob = scales::squish) +\n    facet_grid(rows = vars(Algorithm), cols = vars(Coefficient), labeller = label_parsed) +\n    theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\nFrom these two figures, we can find that:\n\n1. In the results of GWR, spatial heterogeneity is revealed in estimates for all variables.\nAlthough $\\hat{\\beta}_1$ should be constant across the study area,\nGWR still generate spatially varying estimates for it.\nThis is a kind of over-fitting from the spatial perspective.\nBesides, as the bandwidth is small, estimates for $\\gamma_1$ and $\\gamma_2$ are too local.\nConsequently, there are quite a few outliers disrupting the spatial trend.\n2. MGWR partly gets over issues of GWR by adopting parameter-specified bandwidths,\ninstead of a uniform bandwidth.\nAnd it performs better when estimating $\\gamma_1$ and $\\gamma_2$.\nFor global fixed effects, MGWR still generates spatially varying estimates,\nbut they vary much slightly than estimates from GWR.\nFor random effects, the results are slightly smoothed as well.\nMGWR also borrow a few points from neighbors.\nThere is another serious problem in MGWR that it requires too much computing time and memory.\n3. In the results of HLM, there is only one estimate for $\\beta_1$ across the whole area.\nAnd estimates for $\\mu_1$, The problem lies in estimates for $\\gamma_1$ and $\\gamma_2$.\nAs they are fixed effects in HLM, their estimates are also constant for all samples.\nHowever, spatial heterogeneity is expected in them.\n4. HGWR is the final solution.\nFor global fixed effects, it generates globally constant estimates for all samples.\nFor random effects, it would not smooth the estimates because they are not obtained by borrowing points.\nAnd for local fixed effects, we can discover spatial heterogeneity from their estimates.\nAnd it would not repeat computation for samples at each location.\nThus, only the number of locations obviously affects the computation efficiency.\nThis can reduce a large amount of computing time and memory.\n\nThere is an animation demonstrating the problem about bandwidth we addressed above.\n\n{{< video https://hpdell.github.io/hgwr/assets/multisampling.mp4 \n    title='Issues related to the bandwidth in hierarchical spatial data'\n>}}\n\nAs shown in this video, bandwidths have inequal spatial scale for two samples (represented by cubes).\nBoth the samples represented by large red cubes and large blue cubes take 41 neighbour samples to calibrate GWR models.\nFor the red one, neighbours on 8 nearest locations are taken. But the figure for the blue one is only 6.\nThis situation means estimated coefficients are more smoothed for the red samples.\nIn other words, estimations for the blue samples are much local.\n\nHGWR overcome this drawback by introducing hierarchical structure with a special designed backfitting estimator.\nWith the popularity of spatiotemporal big data,\nsituations wherein the specific parameters for which HGWR was optimized are becoming more prevalent,\nsuggesting that HGWR holds considerable promise as a useful tool for analyzing such data sets.\n\n## Estimation Errors\n\nWe can use some indicators to evaulate estimation errors for each model and coefficient.\nThe following code generate a box-plot of absolute coefficient errors $\\mathrm{AE}$, which is\n$$\n\\mathrm{AE}_i = \\left| r_i - e_i \\right|\n$$\nwhere $r_i$ reprsents the real value at sample $i$, and $e_i$ represents the corresponding estimate.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-7_6a16084268636c6384dee12772a8f684'}\n\n```{.r .cell-code}\nmodels_coef %>%\n    map(~ select(.x, all_of(coef_names))) %>%\n    map_dfr(function(x) {\n        map2_dfr(x, names(x), ~ data.frame(ae = ae(beta0[[.y]], .x)), .id = \"Coefficient\")\n    }, .id = \"Algorithm\") %>%\n    mutate(Algorithm = ordered(as.factor(Algorithm), names(models_coef)),\n           Coefficient = ordered(as.factor(Coefficient), coef_names)) %>%\n    arrange(Coefficient, Algorithm) %>%\n    ggplot(aes(x = Coefficient, y = ae, fill = Algorithm)) + geom_boxplot() +\n        scale_y_log10(name = 'Squared Error', labels = ~ sprintf(\"%g\", .x)) +\n        scale_x_discrete(labels = coef_name_labels[coef_names]) +\n        theme_bw() +\n        theme(legend.position = \"top\", axis.text.y = element_text(angle = 90, hjust = 0.5))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nAnd the following code generate a bar-plot showing root mean squared errors $\\mathrm{RMSE}$ of each coefficient, which is\n$$\n\\mathrm{RMSE} = \\sum_{i=1}^n \\left(r_1-e_i\\right)^2\n$$\nwhere $r_i$ reprsents the real value at sample $i$, and $e_i$ represents the corresponding estimate.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-8_f08303866a8148e927e577ae28d05942'}\n\n```{.r .cell-code}\nmodels_coef %>%\n    map_dfr(function (alg) {\n        map_dfr(coef_names, function (coef, real) {\n            est_rmse <- rmse(real[[coef]], alg[[coef]])\n            data.frame(Coefficient = coef, Value = est_rmse)\n        }, beta0)\n    }, .id = \"Algorithm\") %>%\n    mutate(Algorithm = ordered(as.factor(Algorithm), c(\"GWR\", \"MGWR\", \"HLM\", \"HGWR\")),\n           Coefficient = ordered(as.factor(Coefficient), coef_names)) %>%\n    ggplot(aes(x = Coefficient, y = Value, fill = Algorithm)) + \n        geom_bar(stat = 'identity', position = position_dodge()) + ylab(\"RMSE\") +\n        scale_y_continuous(limits = c(0, 1.6), oob = scales::squish, expand = expansion()) +\n        scale_x_discrete(labels = coef_name_labels[coef_names]) +\n        theme_bw() + theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nFrom the perspective of estimation errors, HGWR significantly reduces the estimation error for local fixed effects.\nIt can get over the affect of global fixed effects and random effects.\n\n# Summary\n\nIn this post we introduced how to calibrate an HGWR model using R package **hgwrr**.\nIt is demonstrated that HGWR could properly estimate local fixed effects,\nglobal fixed effects, and random effects simultaneously.\nHGWR could usually successfully distinguish local fixed effects from other effect types.\nFor local fixed effects, spatial heterogeneity is considered as with GWR;\nmoreover, global fixed effects and random effects are estimated as accurately as when using HLM.\nThus, HGWR can be regarded as a successful combination of GWR and HLM.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}