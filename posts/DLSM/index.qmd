---
title: "Introducing a General Framework for Locally Weighted Spatial Modelling Based on Density Regression"
author: "Yigong Hu"
date: "2023-03-22"
bibliography: references.bib
execute: 
  cache: true
---

In this document, I'm going to show codes of simulation experiments and their results demonstrated in the short paper
*Introducing a General Framework for Locally Weighted Spatial Modelling Based on Density Regression*.
This paper mainly talks about a density-based local spatial modelling (DLSM) method,
which was originally named as "geographically weighted density regression (GWDR)".
In the following parts, we don't distinguish these two terms.

In addition to show reproducable code of experiments shown in the paper,
We are going to describe a bit how to install and use this model.

# Installation

The R implementation of GWDR is in the unpublished [`feature-gctwr` branch](https://github.com/GWmodel-Lab/GWmodel2/tree/feature-gctwr)
of package [**GWmodel**](https://cran.r-project.org/web/packages/GWmodel/index.html).
To use it, please clone this repositry, switch to this branch, and install this package manually.

```bash
git clone https://github.com/GWmodel-Lab/GWmodel2.git GWmodel
cd GWmodel
git switch feature-gctwr
R CMD INSTALL GWmodel
```

::: {.callout-warning}
Please install [Rtools](https://cran.r-project.org/bin/windows/Rtools/) if you are using Windows platforms.
:::

When all packages are ready, please go on to the next section.

# Usage

The function `gwdr()` can calibrate a DLSM model according to given formula, data, and other settings.

```r
gwdr <- function(
    formula, data,
    coords, kernel.list, solver = "kernel.smooth", ...
) { ... }
```

It accepts several parameters.
Besides the `formula` and `data` arguments that are constant with other regression models in R,
three additional key arguments are needed: 

`coords`
: Coordinates to uniquely locate every sample.
Coordinates may not only geographical positions, but also positions in other dimensions.
For example, coordinates of spatio-temporal data are geographical positions and the timestamp;
and coordinates of flow data can consist of the geographical positions of origin points, flows' directions, and flows' length.

`kernel.list`
: A list of kernel settings for every dimension.
Each item is a full specification of kernel function (including bandwidth) for a dimension, i.e., a column in `coords`.
It usually has three elements in each item: bandwidth value, kernel name, and adaptive or fixed.
There is a function `gwdr.make.kernel()` that would be helpful in creating elements in `kernel.list`.

`solver`
: The name of favored density estimation method.
By default, its `"kernel.smooth"` referring the kernel smooth estimation.
This estimation method is the same as ordinary GWR-family models, like basic GWR and GTWR.
Currently, there is another option `"local.poly"` for local polynomial estimation.
This method is better at eliminating boundary effects to produce more accurate estimates in the area near to boundaries.
The additional parameter `...` will be passed to the corresponding solver function.

The bandwidth values in `kernel.list` would significantly affect results.
If best values are unknow, there is a function `gwdr.bandwidth.optimize()` to obtain the optimized bandwidth values.

```r
gwdr.bandwidth.optimize <- function(
    formula, data, coords, kernel.list,
    optimize.method = gwdr.bandwidth.optimize.cv,
    solver = "kernel.smooth", ...
) { ... }
```

The former four arguments and `solver` are the same as those in `gwdr()`.
The argument `optimize.method` is used to specify optimization criterion,
i.e., Cross Validation (CV) or Akaike Information Criterion (AIC).
The former one is quicker while the latter one could avoid overfitting.
Note that the underlying algorithm is the Nelder-Meed algorithm, which requires initial values of bandwidths.
Usually, $0.618$ is good for adaptive bandwidths.

# Experiments

In the following codes, the following packages are also required:

- [**tidyverse**](https://cran.r-project.org/web/packages/tidyverse/index.html)
- [**ggpubr**](https://cran.r-project.org/web/packages/ggpubr/index.html)
- [**ggpmisc**](https://cran.r-project.org/web/packages/ggpmisc/index.html)
- [**sf**]()(https://cran.r-project.org/web/packages/sf/index.html)
- [**Metrics**]()(https://cran.r-project.org/web/packages/Metrics/index.html)
- [**reshape2**]()(https://cran.r-project.org/web/packages/reshape2/index.html)

Please install and load them too.

```{r}
#| message: false
#| warning: false

library(GWmodel)
library(tidyverse)
library(ggpubr)
library(ggpmisc)
library(sf)
library(Metrics)
library(reshape2)
```

We carried out three experiments, generating simulation data sets to demonstrate how DLSM works.
We also calibrated a corresponding GWR-family model in each experiment to provide a comparison.
In the experiments, based on the coefficient estimates we examine the proximity to their actual values
by making scatter plot with regression lines and calculate their RMSE and MAE criterions defined by
$$
\begin{aligned}
\mathrm{RMSE} &= \sum_{i=1}^n \left(r_1-e_i\right)^2 \\
\mathrm{MAE} &= \sum_{i=1}^n \left|r_1-e_i\right|
\end{aligned}
$$
where $n$ is the number of estimates, $e_i$ is the $i$-th estimate, and $r_i$ is the corresponding real value.

## Two-dimensional Data

### Data Generating

Data of two dimensions (equalivent to normal geographic data) are generated by the following codes.

```{r d2-datagen}
generate_data_d2 <- function (size) {
  set.seed(11)
  U1 <- rnorm(n = size, mean = 3000, sd = 100)
  set.seed(12)
  U2 <- rnorm(n = size, mean = 3000, sd = 100)
  set.seed(21)
  x1 <- rnorm(n = size, mean = 0, sd = 1)
  set.seed(22)
  x2 <- rnorm(n = size, mean = 0, sd = 1)
  set.seed(23)
  x3 <- rnorm(n = size, mean = 0, sd = 1)
  U1c <- (U1 - 3000) / 100
  U2c <- (U2 - 3000) / 100
  b0 <- U1c + U2c^2
  b1 <- U1c + U2c^2 + 10
  b2 <- U1c + (U2c - 1)^2
  b3 <- U1c + U2c^2 + 2 * U2c
  set.seed(1)
  y <- b0 + b1 * x1 + b2 * x2 + b3 * x3 + rnorm(n = size, mean = 0, sd = 1)
  list(
    data = data.frame(y = y, x1 = x1, x2 = x2, x3 = x3),
    coords = cbind(U1 = U1, U2 = U2),
    beta = data.frame(Intercept = b0, x1 = b1, x2 = b2, x3 = b3)
  )
}
data_d2 <- generate_data_d2(5000)
glimpse(data_d2)
```

Then, calibrate two models: DLSM and basic GWR.

### Model: DLSM

Firstly, we need to get a set of optimized bandwidth, each element for a dimension.

```{r d2-gwdr-bw}
d2_gwdr_bw <- gwdr.bandwidth.optimize(
    formula = y ~ x1 + x2 + x3,
    data = data_d2$data,
    coords = data_d2$coords,
    kernel.list = list(
        gwdr.make.kernel(0.618, kernel = "gaussian", adaptive = T),
        gwdr.make.kernel(0.618, kernel = "gaussian", adaptive = T)
    ),
    optimize.method = gwdr.bandwidth.optimize.aic
)
d2_gwdr_bw
```

Then, calibrate a GWDR model with this bandwidth set.

```{r d2-gwdr-model}
d2_gwdr <- gwdr(
    formula = y ~ x1 + x2 + x3,
    data = data_d2$data,
    coords = data_d2$coords,
    kernel.list = d2_gwdr_bw
)
d2_gwdr$diagnostic
```

### Model: GWR

The GWR model for this data set can be calibrated with the following code.

```{r d2-gwr-model}
d2sp <- data_d2$data
coordinates(d2sp) <- data_d2$coords
d2_gwr_bw <- bw.gwr(
    formula = y ~ x1 + x2 + x3,
    data = d2sp,
    adaptive = T,
    approach = "AIC",
    kernel = "gaussian",
    longlat = F
)
d2_gwr <- gwr.basic(
    formula = y ~ x1 + x2 + x3,
    data = d2sp,
    bw = d2_gwr_bw,
    adaptive = T,
    kernel = "gaussian",
    longlat = F
)
d2_gwr
```

Whereas DLSM helps identify anisotropy, it is missing in estimates from a basic GWR model
because the only bandwidth value optimized by GWR is 16 nearest neighbours (regardless of direction).

### Analysis of Coefficient Estimates

First, we look at the closeness between coefficient estimates and actual values.

```{r}
list(DLSM = d2_gwdr$betas, GWR = d2_gwr$SDF@data) %>%
    map(~ select(.x, Intercept, x1, x2, x3)) %>%
    map2_dfr(., names(.), function(model, model_name) {
        map_dfr(c("Intercept", "x1", "x2", "x3"), ~ data.frame(
            Estimated = model[[.x]],
            Real = data_d2$beta[[.x]],
            Coefficient = .x
        ))
    }, .id = "Model") %>%
    ggplot(aes(x = Real, y = Estimated)) + geom_point() +
    geom_abline(intercept = 0, slope = 1, color = "darkgreen") +
    stat_poly_eq() + stat_poly_line() +
    facet_grid(rows = vars(Model), cols = vars(Coefficient)) +
    coord_fixed() + theme_bw()
```

Then, we look at the RMSE and MAE criterions.

```{r}
list(DLSM = d2_gwdr$betas, GWR = d2_gwr$SDF@data) %>%
    map(~ select(.x, Intercept, x1, x2, x3)) %>%
    map2_dfr(., names(.), function(model, model_name) {
        map_dfr(c("Intercept", "x1", "x2", "x3"), ~ data.frame(
            RMSE = sqrt(mean((data_d2$beta[[.x]] - model[[.x]])^2)),
            MAE = mean(abs(data_d2$beta[[.x]] - model[[.x]])),
            Coefficient = .x
        ))
    }, .id = "Model") %>%
    map_dfr(c("RMSE", "MAE"), function(i, model) {
        data.frame(Value = model[[i]],
                   Indicator = i,
                   Model = model$Model,
                   Coefficient = model$Coefficient)
    }, .) %>%
    ggplot(aes(x = Coefficient, y = Value, fill = Model)) + 
    geom_col(position = "dodge") +
    geom_text(aes(y = Value + 0.02, label = sprintf("%.2f", Value)),
              position = position_dodge(width = 1)) +
    facet_grid(cols = vars(Indicator)) +
    theme_bw() + theme(legend.position = "top")
```

### Local Polynomial Estimator

Coefficient estimates for some points are significantly biased in both DLSM and GWR models.
Now let us try the local polynomial kernel estimation method to demonstrate some of its features.
We will calibrate a DLSM model with this kernel analyse coefficient estimates in a same way.

```{r d2-gwdr-model-lp}
d2_gwdr_lp <- gwdr(
    formula = y ~ x1 + x2 + x3,
    data = data_d2$data,
    coords = data_d2$coords,
    kernel.list = d2_gwdr_bw,
    solver = "local.poly"
)
d2_gwdr$diagnostic
```

The following two figures show comparsion between estimates and real values.

```{r}
#| echo: false

list(DLSM = d2_gwdr_lp$betas, GWR = d2_gwr$SDF@data) %>%
    map(~ select(.x, Intercept, x1, x2, x3)) %>%
    map2_dfr(., names(.), function(model, model_name) {
        map_dfr(c("Intercept", "x1", "x2", "x3"), ~ data.frame(
            Estimated = model[[.x]],
            Real = data_d2$beta[[.x]],
            Coefficient = .x
        ))
    }, .id = "Model") %>%
    ggplot(aes(x = Real, y = Estimated)) + geom_point() +
    geom_abline(intercept = 0, slope = 1, color = "darkgreen") +
    stat_poly_eq(use_label("adj.rr.label")) + stat_poly_line() +
    facet_grid(rows = vars(Model), cols = vars(Coefficient)) +
    coord_fixed() + theme_bw()

list(DLSM = d2_gwdr_lp$betas, GWR = d2_gwr$SDF@data) %>%
    map(~ select(.x, Intercept, x1, x2, x3)) %>%
    map2_dfr(., names(.), function(model, model_name) {
        map_dfr(c("Intercept", "x1", "x2", "x3"), ~ data.frame(
            RMSE = sqrt(mean((data_d2$beta[[.x]] - model[[.x]])^2)),
            MAE = mean(abs(data_d2$beta[[.x]] - model[[.x]])),
            Coefficient = .x
        ))
    }, .id = "Model") %>%
    map_dfr(c("RMSE", "MAE"), function(i, model) {
        data.frame(Value = model[[i]],
                   Indicator = i,
                   Model = model$Model,
                   Coefficient = model$Coefficient)
    }, .) %>%
    ggplot(aes(x = Coefficient, y = Value, fill = Model)) + 
    geom_col(position = "dodge") +
    geom_text(aes(y = Value + 0.02, label = sprintf("%.2f", Value)),
              position = position_dodge(width = 1)) +
    facet_grid(cols = vars(Indicator)) +
    theme_bw() + theme(legend.position = "top")
```

Thus, the local polynomial estimator can significantly reduce estimation errors.
And the boundary effects are also reduced.

## Three-dimensional Data

In most spatial modelling research, 3D data are usually referred to spatio-temporal data, i.e., data of geographical and temporal coordinates $u,v,t$.
For this type of data, there is a corresponding geographically and temporally weighted regression [GTWR, @HuangWu-2010a] model.
In this experiment, we compare DLSM model with this method.

### Data

We created 4 sets of data through similar generation process introduced in the experiment on 2D data,
named as `data-3d-i` where `i` is a value from 1 to 4.
To access these data, please turn to [GitHub worktree page](https://github.com/HPDell/GIScience-Materials/tree/master/posts/DLSM/data).

```{r d3-data}
d3_data_list <- map(c(1:4), function(i) {
    readRDS(sprintf("data/compare-gtwr-%d.rds", i))
})
```

In the first two data sets, the time coordinates were generated from a normal distributed random variable, i.e., $t \sim N(1619694000, 604800^2)$.
While in the latter two data sets, $t$ was generated from an arithmetic sequence with 1000 elements, a common different of 1, and a first item $t_0$ of $1619694000$.
And the distribution of coefficients on $t$-axis follows autoregressive time series.

### Model: DLSM

The DLSM model can be calibrated with the following codes:

```{r d3-gwdr}
#| message: false

d3_gwdr_list <- map(c(1:4), function (i) {
    d3_data <- d3_data_list[[i]]
    coords_range <- apply(d3_data$coord, 2, max) - apply(d3_data$coord, 2, min)
    kernel <- gwdr.bandwidth.optimize(
        formula = y ~ x1 + x2 + x3,
        data = d3_data$data,
        coords = d3_data$coord,
        kernel.list = list(
            gwdr.make.kernel(coords_range[1] * 0.618, kernel = "bisquare", adaptive = FALSE),
            gwdr.make.kernel(coords_range[2] * 0.618, kernel = "bisquare", adaptive = FALSE),
            gwdr.make.kernel(coords_range[3] * 0.618, kernel = "bisquare", adaptive = FALSE)
        )
    )
    gwdr(
        formula = y ~ x1 + x2 + x3,
        data = d3_data$data,
        coords = d3_data$coord,
        kernel.list = kernel
    )
})
```

### Model: GTWR

We used the "[GTWR ADDIN](https://www.researchgate.net/publication/329518786_GTWR_ADDIN_Valid_till_Dec_31_2022)" for ArcMap [@gtwr-addin]
to calibrate GTWR model for all the four data sets.
This is because there is a key parameter $\lambda$ in GTWR mdoel which should be optimized according to data, just like the bandwidth.
But `gtwr()` function in **GWmodel** package does not support this process.
And this addin has much higher computing performance.
Results are stored in the [GTWR results folder](https://github.com/HPDell/GIScience-Materials/tree/master/posts/DLSM/gtwr_results).
We can load them with the following codes.

```{r d3-gtwr}
#| message: false

d3_gtwr_list <- map(c(1:4), function(i) {
    st_read(file.path("gtwr_results", sprintf("compare-gtwr-%d-gtwr.shp", i)))
})
```

### Analysis

We analyse the performance of these two models based on coefficient estimates and actual values.

```{r}
d3_model_coef <- pmap(list(
    DLSM = d3_gwdr_list,
    GTWR = d3_gtwr_list,
    Real = d3_data_list
), function(DLSM, GTWR, Real) {
    dlsm_coef_df <- select(DLSM$betas, Intercept, x1, x2, x3) %>%
        map2_dfr(., names(.), ~ data.frame(
            Model = "DLSM",
            Coefficient = .y,
            Estimate = .x,
            Real = Real$beta[[.y]]
        ))
    gtwr_coef_df <- rename(GTWR, x1 = C1_x1, x2 = C2_x2, x3 = C3_x3) %>%
        st_drop_geometry() %>%
        select(Intercept, x1, x2, x3) %>%
        map2_dfr(., names(.), ~ data.frame(
            Model = "GTWR",
            Coefficient = .y,
            Estimate = .x,
            Real = Real$beta[[.y]]
        ))
    rbind(dlsm_coef_df, gtwr_coef_df)
})
```

```{r}
#| message: false
#| warning: false

d3_model_coef %>%
    map(function(item) {
        scatter <- ggplot(item, aes(Real, Estimate)) +
            geom_point() +
            geom_abline(intercept = 0, slope = 1) +
            geom_smooth(method = "lm") +
            stat_poly_eq(use_label("adj.rr.label")) +
            facet_grid(rows = vars(Coefficient), cols = vars(Model)) +
            coord_fixed() + theme_bw()
        bar <- item %>%
            group_by(Coefficient, Model) %>%
            summarise(RMSE = rmse(Real, Estimate), MAE = mae(Real, Estimate)) %>%
            ungroup() %>%
            melt(id.vars = c("Coefficient", "Model"), variable.name = "Indicator", value.name = "Value") %>%
            ggplot(aes(Coefficient, Value, fill = Model)) +
                geom_col(position = "dodge") +
                geom_text(aes(label = sprintf("%.2f", Value)), size = 2,
                        position = position_dodge(1), vjust = -0.5) +
                facet_grid(rows = vars(Indicator)) +
                theme_bw()
        ggarrange(scatter, bar, nrow = 1)
    }) %>%
    walk2(., 1:4, function(fig, i) {
        print(annotate_figure(fig, bottom = sprintf("Data set %d", i)))
    })
```

According to the results, DLSM can reduce the mean of absolute estimation error by 10%-50%, especially when coefficients are temporally autocorrelated.
The multiple bandwidths attach actual meaning to the parameters $\lambda,\mu$; they have a real-world correlate,
unlike the root of sum of squared meters and seconds ($\sqrt{\mathrm{m}^2+\mathrm{s}^2}$).

## Four-dimensional Data

Four-dimensional data are not so common in our daily life.
But there is an special example --- travel flow.
Each flow is a directed line consisting of a origin point and destination point.
Thus, flow data are also called O-D data.
For a 2D coordinate reference system, both the origin point and desitnation point have a 2D coordinates.
Totally, there are 4 coordinates to locate a flow.
By converting the four positional coordinates to a set of coordinates of origin point $(x,y)$, direction $\theta$, and flow length $l$,
we will get a space of four dimensions $(x,y,\theta,l)$.
The experiment is based on this space.

### Data Generating

Data of four dimensions are generated by the following codes.

```{r d4-data-gen}
generate_data_d4 <- function (size) {
  set.seed(11)
  U1 <- rnorm(n = size, mean = 3000, sd = 100)
  set.seed(12)
  U2 <- rnorm(n = size, mean = 3000, sd = 100)
  set.seed(13)
  U3 <- runif(n = size, min = -pi, max = pi)
  set.seed(14)
  U4 <- rnorm(n = size, mean = 4000, sd = 1000)
  set.seed(21)
  x1 <- rnorm(n = size, mean = 0, sd = 1)
  set.seed(22)
  x2 <- rnorm(n = size, mean = 0, sd = 1)
  set.seed(23)
  x3 <- rnorm(n = size, mean = 0, sd = 1)
  b0 <- scale(((U1 - 3000)/100) + ((U2 - 3000)/100)^2 + ((U4 - 4000)/1000)^2)
  b1 <- scale(((U1 - 3000)/100) + ((U2 - 3000)/100)^2 + ((U4 - 4000)/1000)^2)
  b2 <- scale(((U1 - 3000)/100) + 5 * ((U2 - 3000)/100)^2 + ((U4 - 4000)/1000)^2)
  b3 <- scale(-((U1 - 3000)/100) + ((U2 - 3000)/100)^2 + ((U4 - 4000)/1000)^2)
  set.seed(1)
  y <- b0 + b1 * x1 + b2 * x2 + b3 *x3 + rnorm(n = size, mean = 0, sd = 1)
  list(
    data = data.frame(y = y, x1 = x1, x2 = x2, x3 = x3),
    coords = cbind(U1 = U1, U2 = U2, U3 = U3, U4 = U4),
    beta = data.frame(Intercept = b0, x1 = b1, x2 = b2, x3 = b3)
  )
}
data_d4 <- generate_data_d4(5000)
```

### Model: DLSM

The DLSM model can be calibrated by the following code.

```{r d4-dlsm-model}
d4_gwdr_bw <- gwdr.bandwidth.optimize(
    formula = y ~ x1 + x2 + x3,
    data = data_d4$data,
    coords = data_d4$coords,
    kernel.list = list(
        gwdr.make.kernel(0.618, kernel = "bisquare", adaptive = T),
        gwdr.make.kernel(0.618, kernel = "bisquare", adaptive = T),
        gwdr.make.kernel(0.618, kernel = "bisquare", adaptive = T),
        gwdr.make.kernel(0.618, kernel = "bisquare", adaptive = T)
    )
)
d4_gwdr <- gwdr(
    formula = y ~ x1 + x2 + x3,
    data = data_d4$data,
    coords = data_d4$coords,
    kernel.list = d4_gwdr_bw
)
d4_gwdr$diagnostic
```

### Model: GWR

To calibrate a GWR model, we need to calculate the distance matrix first because `gwr.basic()` is not able to calculate distances for lines.
Distance between two flows $\overrightarrow{O_iD_i}$ and $\overrightarrow{O_jD_j}$ are defined by
$$
d_{ij}=\sqrt{\frac{
    0.5 \times \left[ (O_{ix}-O_{jx})^2 + (O_{iy}-O_{jy})^2 \right] +
    0.5 \times \left[ (D_{ix}-D_{jx})^2 + (D_{iy}-D_{jy})^2 \right]
}{l_i l_j}}
$$
where $(O_{ix},O_{iy})$ is the coordinate of $O_i$,
$(O_{jx},O_{jy})$ is the coordinate of $O_j$,
$(D_{ix},D_{iy})$ is the coordinate of $D_i$,
$(D_{jx},D_{jy})$ is the coordinate of $D_j$,
and $l_i,l_j$ are length of  flows $\overrightarrow{O_iD_i}$ and $\overrightarrow{O_jD_j}$.

This is implementated by the following codes.

```{r d4-gwr-dmat}
d4_origin <- data_d4$coords[, 1:2]
d4_dest <- d4_origin + with(as.data.frame(data_d4$coords), matrix(cbind(U4 * cos(U3), U4 * sin(U3)), ncol = 2))
d4_od <- cbind(d4_origin, d4_dest, data_d4$coords[, 3:4])
colnames(d4_od) <- c("ox", "oy", "dx", "dy", "angle", "length")
d4_dmat <- apply(d4_od, MARGIN = 1, FUN = function(x) {
    sqrt(colSums((t(d4_od[,1:4]) - x[1:4])^2) / 2 / x["length"] / d4_od[, "length"])
})
d4_dmat[1:5,1:5]
```

Then use the distance matrix `d4_dmat` as weighting criterion in GWR.

```{r d4-gwr-model}
d4sp <- cbind(data_d4$data)
coordinates(d4sp) <- data_d4$coords[,1:2]
d4_gwr_bw <- bw.gwr(
    formula = y ~ x1 + x2 + x3, data = d4sp,
    adaptive = T, dMat = d4_dmat
)
d4_gwr <- gwr.basic(
    formula = y ~ x1 + x2 + x3, data = d4sp,
    bw = d4_gwr_bw, adaptive = T, dMat = d4_dmat
)
d4_gwr
```

### Analysis

Closeness between coefficient estimates and actual values are shown in the following figure.

```{r}
list(DLSM = d4_gwdr$betas, GWR = d4_gwr$SDF@data) %>%
    map(~ select(.x, Intercept, x1, x2, x3)) %>%
    map2_dfr(., names(.), function(model, model_name) {
        map_dfr(c("Intercept", "x1", "x2", "x3"), ~ data.frame(
            Estimated = model[[.x]],
            Real = data_d4$beta[[.x]],
            Model = model_name,
            Coefficient = .x
        ))
    }) %>%
    ggplot(aes(x = Real, y = Estimated)) + geom_point() +
    geom_abline(intercept = 0, slope = 1, color = "darkgreen") +
    stat_poly_eq() + stat_poly_line() +
    facet_grid(rows = vars(Model), cols = vars(Coefficient)) +
    theme_bw()
```

RMSE and MAE evaluations are shown in the following figure.

```{r}
list(DLSM = d4_gwdr$betas, GWR = d4_gwr$SDF@data) %>%
    map(~ select(.x, Intercept, x1, x2, x3)) %>%
    map2_dfr(., names(.), function(model, model_name) {
        map_dfr(c("Intercept", "x1", "x2", "x3"), ~ data.frame(
            RMSE = sqrt(mean((data_d4$beta[[.x]] - model[[.x]])^2)),
            MAE = mean(abs(data_d4$beta[[.x]] - model[[.x]])),
            Model = model_name,
            Coefficient = .x
        ))
    }) %>%
    map_dfr(c("RMSE", "MAE"), function(i, model) {
        data.frame(Value = model[[i]],
                   Indicator = i,
                   Model = model$Model,
                   Coefficient = model$Coefficient)
    }, .) %>%
    ggplot(aes(x = Coefficient, y = Value, fill = Model)) + 
    geom_col(position = "dodge") +
    geom_text(aes(y = Value + 0.02, label = sprintf("%.2f", Value)),
              position = position_dodge(width = 1)) +
    facet_grid(cols = vars(Indicator)) +
    theme_bw() + theme(legend.position = "top")
```

Results show that DLSM works well for spatial line data even without defining distance metrics.
It performs better than GWR according to mean of estimation errors, but a few outliers exist in estimates.
GWR selected a much smaller bandwidth (173 neighbours).
Thus, the risk of overfitting reappears.

# Summary

In this post, the usage and some examples for DLSM is demonstrated.
It offers more flexibility because of its three alterable parts:
a space where samples exist, a set of kernels selected for every dimension and a locally weighted regression method.
Simulation shows that DLSM can be applied to many kinds of spatial data without specially defined distance metrics,
such as spatio-temporal data and spatial interaction data.
It can also help tackle the effects of anisotropy because it has, in effect, 
a multidimensional bandwidth and decay function, measuring “closeness” in multiple dimensions simultaneously. 
In the future, researchers no longer need to design distance metrics to bring together, 
in a rather ad hoc way, different types of space and coordinate systems into the distance decay function. 
Assigning a weighting scheme to each of the dimensions and then pooling across them is suggested as a better alternative.
